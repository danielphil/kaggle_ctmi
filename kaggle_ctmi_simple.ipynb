{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A maximally simple solution to CT / CTA detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('precision', 2)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pydicom\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "from skimage.transform import downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading DICOM from the SHAIP environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICOM_PATH = 'data/dicom_dir/'\n",
    "SMILY = u'\\U0001F603'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cohort(object):\n",
    "    \"\"\" \n",
    "    Manages a SHAIP-like cohort of datasets, finding what datasets are available, reading data and GT.\n",
    "    Deals only with the raw input data - no normalization happens here.  \n",
    "    Accessors generally present lazy evaluation semantics.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" The constructor scans the data path to find what data is present and\n",
    "        setup a list and dictionary of dataset ids and paths.  It does not *read*\n",
    "        the data\"\"\"\n",
    "        self.dicom_path = 'data/dicom_dir/'\n",
    "        self.filepaths = glob(DICOM_PATH + '*.dcm')\n",
    "        self.ids = [os.path.basename(fp)[:7] for fp in self.filepaths]\n",
    "        self.id_to_path_map = {id: path for id, path in zip(self.ids, self.filepaths)}\n",
    "        self.size = len(self.ids)\n",
    "        \n",
    "        # Private cache storage\n",
    "        self._images = self._dicoms = self._groundtruth = None\n",
    "        \n",
    "    @property\n",
    "    def dicoms(self):\n",
    "        \"\"\" Lazily read and return a list of dicom objects in the same order as self.ids \"\"\"\n",
    "        if self._dicoms is None:\n",
    "            self._dicoms = [pydicom.dcmread(fp) for fp in self.filepaths]\n",
    "        return self._dicoms\n",
    "        \n",
    "    @property\n",
    "    def images(self):\n",
    "        \"\"\" Lazily extract and a list of images (2d numpy arrays) in the same order as self.ids \"\"\"\n",
    "        if self._images is None:\n",
    "            self._images = [dcm.pixel_array for dcm in self.dicoms]\n",
    "        return self._images\n",
    "    \n",
    "    @staticmethod\n",
    "    def _filename_to_contrast_gt(fname):\n",
    "        \"\"\" Filenames look like this: \"ID_0087_AGE_0044_CONTRAST_0_CT.dcm \"\"\"\n",
    "        assert fname[17:25] == 'CONTRAST'\n",
    "        c = fname[26]\n",
    "        assert c in ('0', '1')\n",
    "        return int(c)\n",
    "        \n",
    "    @property\n",
    "    def groundtruth(self):\n",
    "        \"\"\" Return a list of ground-truth values as {0, 1} integers in the same order as self.ids\"\"\"\n",
    "        if self._groundtruth is None:\n",
    "            self._groundtruth = [Cohort._filename_to_contrast_gt(os.path.basename(fp)) for fp in self.filepaths]\n",
    "        return self._groundtruth\n",
    "            \n",
    "\n",
    "def test_cohort_init():\n",
    "    cohort = Cohort()\n",
    "    # print(datasets.ids)\n",
    "    # print(datasets.id_to_path_map)\n",
    "    assert len(cohort.ids) == 100\n",
    "    assert len(cohort.ids[0]) == 7 and cohort.ids[0][:3] == 'ID_'\n",
    "    assert os.path.exists(cohort.filepaths[0])\n",
    "    print(SMILY, \"test_cohort_init passed.\")\n",
    "    \n",
    "def test_cohort_accessors():\n",
    "    cohort = Cohort()\n",
    "    assert len(cohort.dicoms) == len(cohort.ids) == len(cohort.images) == \\\n",
    "           len(cohort.groundtruth) == len(cohort.groundtruth) == len(cohort.filepaths) == cohort.size\n",
    "    assert all(['PixelData' in dcm for dcm in cohort.dicoms])\n",
    "    assert len(cohort.images) == len(cohort.ids)\n",
    "    assert all([im.shape == (512, 512) for im in cohort.images])\n",
    "    assert all([im.dtype in (np.int16, np.uint16) for im in cohort.images])\n",
    "    assert all([gt in (0,1) for gt in cohort.groundtruth])\n",
    "    print(SMILY, \"test_cohort_accessors passed.\")\n",
    "                    \n",
    "def test__filename_to_contrast_gt():\n",
    "    fname = 'ID_0087_AGE_0044_CONTRAST_0_CT.dcm'\n",
    "    gt = Cohort._filename_to_contrast_gt(fname)\n",
    "    assert gt == 0\n",
    "    print(SMILY, \"test__filename_to_contrast_gt passed.\")\n",
    "    \n",
    "\n",
    "test__filename_to_contrast_gt()\n",
    "test_cohort_init()\n",
    "test_cohort_accessors()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explore_cohort():\n",
    "    cohort = Cohort()\n",
    "    df = pd.DataFrame(columns=['ID', 'MinV', 'MaxV', 'Slope', 'Incpt', 'MmPerPix', 'Padding'])\n",
    "    for ix in range(cohort.size):\n",
    "        image = cohort.images[ix]\n",
    "        dcm = cohort.dicoms[ix]\n",
    "        id_ = cohort.ids[ix]\n",
    "        padding = dcm.data_element('PixelPaddingValue').value if 'PixelPaddingValue' in dcm else None\n",
    "        slope = dcm.data_element('RescaleSlope').value\n",
    "        intercept = dcm.data_element('RescaleIntercept').value\n",
    "        mmpp_x, mmpp_y = dcm.data_element('PixelSpacing').value\n",
    "        assert mmpp_x == mmpp_y\n",
    "        row = (id_, np.min(image), np.max(image), slope, intercept, mmpp_x, padding)\n",
    "\n",
    "        df.loc[ix] = row\n",
    "        \n",
    "    display(df.describe(include='all'))\n",
    "    display(df)\n",
    "        \n",
    "explore_cohort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(cohort):\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(16,16))\n",
    "    for ix, ax in enumerate(axes.flat):   # Show just a selection\n",
    "        im = cohort.images[ix]\n",
    "        gt = cohort.groundtruth[ix]\n",
    "        pltim = ax.imshow(im)\n",
    "        ax.set_title(\"%s GT=%d\"% (cohort.ids[ix], gt))\n",
    "        cbar=fig.colorbar(pltim, ax=ax)\n",
    "    plt.show()\n",
    "        \n",
    "show_images(cohort=Cohort())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedCohort(object):\n",
    "    \"\"\" \n",
    "    Represents cohort of data with basic pre-procession applied.  For example, deal with padding,\n",
    "    conversion to Hounsfield etc.  At this stage we are no longer concerned with file formats, directories\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    downsample_factor = (4, 4)\n",
    "    imshape = tuple(512//dsf for dsf in downsample_factor)\n",
    "    \n",
    "    def __init__(self, cohort):\n",
    "        dicoms = cohort.dicoms\n",
    "        \n",
    "        self.size = cohort.size   # Number of images\n",
    "        self.ids = cohort.ids\n",
    "        self.groundtruth = cohort.groundtruth\n",
    "        self.dicoms = cohort.dicoms\n",
    "        \n",
    "        self._preprocessed_images = None\n",
    "        \n",
    "    def _preprocess_one_dicom(self, dcm):\n",
    "        \"\"\" Return a nicely normalised numpy float32 image \"\"\"\n",
    "        raw_image = dcm.pixel_array\n",
    "        padding = dcm.data_element('PixelPaddingValue').value if 'PixelPaddingValue' in dcm else None\n",
    "        # print(raw_image.dtype)\n",
    "        slope = dcm.data_element('RescaleSlope').value\n",
    "        intercept = dcm.data_element('RescaleIntercept').value\n",
    "        \n",
    "        image = np.array(raw_image, dtype=np.float32)\n",
    "        image = image * slope + intercept\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "       \n",
    "        # It seems that padding value lies!  So we'll just clamp image values and hope for the best!\n",
    "        # print(\"Image (min,max) = (%6.1f, %6.1f)\" % (np.min(image), np.max(image)))\n",
    "        clip_min = -200.0\n",
    "        clip_max = 1000.0\n",
    "        image[image < clip_min] = clip_min\n",
    "        image[image > clip_max] = clip_max\n",
    "            \n",
    "        assert np.min(image) >= clip_min\n",
    "        assert np.max(image) <= clip_max\n",
    "        \n",
    "        # Finally, downscale !\n",
    "    \n",
    "        image = downscale_local_mean(image, self.downsample_factor)\n",
    "            \n",
    "        return image\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def images(self):\n",
    "        \"\"\" Lazily apply normalisation \"\"\"\n",
    "        if self._preprocessed_images is None:\n",
    "            self._preprocessed_images = [self._preprocess_one_dicom(dcm) for dcm in self.dicoms]\n",
    "        return self._preprocessed_images\n",
    "    \n",
    "def test__preprocess_one_dicom():\n",
    "    cohort = Cohort()\n",
    "    ppch = PreprocessedCohort(cohort)\n",
    "    dcm1 = cohort.dicoms[0]\n",
    "    image = ppch._preprocess_one_dicom(dcm1)\n",
    "    assert image.shape == PreprocessedCohort.imshape\n",
    "    plt.imshow(image)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print(SMILY, \"test__preprocess_one_dicom passed.\")\n",
    "    \n",
    "def test_preprocessed_cohort_accessors():\n",
    "    ppch = PreprocessedCohort(Cohort())\n",
    "    assert len(ppch.images) == len(ppch.ids) == len(ppch.groundtruth) == ppch.size\n",
    "    print(SMILY, \"test_preprocessed_cohort_accessors passed.\")\n",
    "    \n",
    "test__preprocess_one_dicom()\n",
    "test_preprocessed_cohort_accessors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(PreprocessedCohort(Cohort()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(2, 2),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppch = PreprocessedCohort(Cohort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siz = PreprocessedCohort.imshape\n",
    "x_data = np.array(ppch.images).reshape(-1, siz[0], siz[1], 1)\n",
    "x_data = x_data / 500.0 - 0.5\n",
    "print(x_data.shape, np.min(x_data), np.max(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = keras.utils.to_categorical(ppch.groundtruth, 2)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 70\n",
    "x_train = x_data[:ntrain,:,:,:]\n",
    "x_test = x_data[ntrain:,:,:,:]\n",
    "\n",
    "y_train = y_data[:ntrain,:]\n",
    "y_test = y_data[ntrain:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "\n",
    "history = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs=20,\n",
    "          verbose=1,\n",
    "          validation_split=0.2,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: %5.3f' % score[0])\n",
    "print('Test accuracy %5.3f:' % score[1])\n",
    "epochs = range(1, len(history.acc)+1)\n",
    "plt.plot(epochs, history.acc, label='Train')\n",
    "plt.plot(epochs, history.val_acc, label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
