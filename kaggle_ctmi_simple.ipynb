{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A maximally simple solution to CT / CTA detection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.set_option('precision', 2)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pydicom\n",
    "import os\n",
    "from glob import glob\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras.models import Sequential, model_from_json\n",
    "\n",
    "from skimage.transform import downscale_local_mean\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading DICOM from the SHAIP environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMILY = u'\\U0001F603'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShaipWorkspace(object):\n",
    "    \"\"\" \n",
    "    This trivial class represents the shape (sic) of the SHAIP workspace,\n",
    "    Defining where to find input datasets and GT, where to save results\n",
    "    and models and where to find cache storage.  These are all Docker\n",
    "    container local file paths.   \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data_dir =           'ShaipWorkspace/inputs/dicomdata/'    # Will change\n",
    "        self.groundtruth_dir =    'ShaipWorkspace/inputs/groundtruth/'  # Not yet used (taken from filename!)\n",
    "        self.results_dir =        'ShaipWorkspace/outputs/results/'\n",
    "        self.models_dir =         'ShaipWorkspace/outputs/models/'\n",
    "        self.tensorboad_dir =     'ShaipWorkspace/outputs/tensorboard/' # Not yet used\n",
    "        self.cache_dir =          'ShaipWorkspace/cache/'               # not yet used\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cohort(object):\n",
    "    \"\"\" \n",
    "    Manages a SHAIP-like cohort of datasets, finding what datasets are available, reading data and GT.\n",
    "    Deals only with the raw input data - no normalization happens here.  \n",
    "    Accessors generally present lazy evaluation semantics.\n",
    "    \"\"\"\n",
    "    def __init__(self, shaip):\n",
    "        \"\"\" The constructor scans the data path to find what data is present and\n",
    "        setup a list and dictionary of dataset ids and paths.  It does not *read*\n",
    "        the data\"\"\"\n",
    "        self.shaip = shaip\n",
    "        self.filepaths = glob(self.shaip.data_dir + '*.dcm')\n",
    "        self.ids = [os.path.basename(fp)[:7] for fp in self.filepaths]\n",
    "        self.id_to_path_map = {id: path for id, path in zip(self.ids, self.filepaths)}\n",
    "        self.size = len(self.ids)\n",
    "        \n",
    "        # Private cache storage\n",
    "        self._images = self._dicoms = self._groundtruth = None\n",
    "        \n",
    "    @property\n",
    "    def dicoms(self):\n",
    "        \"\"\" Lazily read and return a list of dicom objects in the same order as self.ids \"\"\"\n",
    "        if self._dicoms is None:\n",
    "            self._dicoms = [pydicom.dcmread(fp) for fp in self.filepaths]\n",
    "        return self._dicoms\n",
    "        \n",
    "    @property\n",
    "    def images(self):\n",
    "        \"\"\" Lazily extract and a list of images (2d numpy arrays) in the same order as self.ids \"\"\"\n",
    "        if self._images is None:\n",
    "            self._images = [dcm.pixel_array for dcm in self.dicoms]\n",
    "        return self._images\n",
    "    \n",
    "    @staticmethod\n",
    "    def _filename_to_contrast_gt(fname):\n",
    "        \"\"\" Filenames look like this: \"ID_0087_AGE_0044_CONTRAST_0_CT.dcm \"\"\"\n",
    "        assert fname[17:25] == 'CONTRAST'\n",
    "        c = fname[26]\n",
    "        assert c in ('0', '1')\n",
    "        return int(c)\n",
    "        \n",
    "    @property\n",
    "    def groundtruth(self):\n",
    "        \"\"\" Return a list of ground-truth values as {0, 1} integers in the same order as self.ids\"\"\"\n",
    "        if self._groundtruth is None:\n",
    "            self._groundtruth = [Cohort._filename_to_contrast_gt(os.path.basename(fp)) for fp in self.filepaths]\n",
    "        return self._groundtruth\n",
    "            \n",
    "\n",
    "def test_cohort_init():\n",
    "    cohort = Cohort(ShaipWorkspace())\n",
    "    # print(datasets.ids)\n",
    "    # print(datasets.id_to_path_map)\n",
    "    assert len(cohort.ids) == 100\n",
    "    assert len(cohort.ids[0]) == 7 and cohort.ids[0][:3] == 'ID_'\n",
    "    assert os.path.exists(cohort.filepaths[0])\n",
    "    print(SMILY, \"test_cohort_init passed.\")\n",
    "    \n",
    "def test_cohort_accessors():\n",
    "    cohort = Cohort(ShaipWorkspace())\n",
    "    assert len(cohort.dicoms) == len(cohort.ids) == len(cohort.images) == \\\n",
    "           len(cohort.groundtruth) == len(cohort.groundtruth) == len(cohort.filepaths) == cohort.size\n",
    "    assert all(['PixelData' in dcm for dcm in cohort.dicoms])\n",
    "    assert len(cohort.images) == len(cohort.ids)\n",
    "    assert all([im.shape == (512, 512) for im in cohort.images])\n",
    "    assert all([im.dtype in (np.int16, np.uint16) for im in cohort.images])\n",
    "    assert all([gt in (0,1) for gt in cohort.groundtruth])\n",
    "    print(SMILY, \"test_cohort_accessors passed.\")\n",
    "                    \n",
    "def test__filename_to_contrast_gt():\n",
    "    fname = 'ID_0087_AGE_0044_CONTRAST_0_CT.dcm'\n",
    "    gt = Cohort._filename_to_contrast_gt(fname)\n",
    "    assert gt == 0\n",
    "    print(SMILY, \"test__filename_to_contrast_gt passed.\")\n",
    "    \n",
    "\n",
    "test__filename_to_contrast_gt()\n",
    "test_cohort_init()\n",
    "test_cohort_accessors()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def explore_cohort(cohort, savefilename=None):\n",
    "    df = pd.DataFrame(columns=['ID', 'GT', 'Dtype', 'MinV', 'MaxV', 'Slope', 'Incpt', 'MmPerPix', 'Padding'])\n",
    "    for ix in range(cohort.size):\n",
    "        image = cohort.images[ix]\n",
    "        dtype = image.dtype\n",
    "        dcm = cohort.dicoms[ix]\n",
    "        id_ = cohort.ids[ix]\n",
    "        gt = cohort.groundtruth[ix]\n",
    "        padding = dcm.data_element('PixelPaddingValue').value if 'PixelPaddingValue' in dcm else None\n",
    "        slope = dcm.data_element('RescaleSlope').value\n",
    "        intercept = dcm.data_element('RescaleIntercept').value\n",
    "        min_, max_ = float(np.min(image)), float(np.max(image))\n",
    "        mmpp_x, mmpp_y = dcm.data_element('PixelSpacing').value\n",
    "        assert mmpp_x == mmpp_y\n",
    "        row = (id_, gt, dtype, min_, max_, slope, intercept, mmpp_x, padding)\n",
    "\n",
    "        df.loc[ix] = row\n",
    "        \n",
    "    display(df.describe(include='all'))\n",
    "    display(df)\n",
    "    if savefilename is not None:\n",
    "        with open(cohort.shaip.results_dir + savefilename, 'w') as fp:\n",
    "            df.to_html(fp)\n",
    "        \n",
    "explore_cohort(Cohort(ShaipWorkspace()), 'summary.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(cohort, savefilename=None):\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(16,16))\n",
    "    for ix, ax in enumerate(axes.flat):   # Show just a selection\n",
    "        im = cohort.images[ix]\n",
    "        gt = cohort.groundtruth[ix]\n",
    "        pltim = ax.imshow(im)\n",
    "        ax.set_title(\"%s GT=%d\"% (cohort.ids[ix], gt))\n",
    "        cbar=fig.colorbar(pltim, ax=ax)\n",
    "    if savefilename is not None:\n",
    "        plt.savefig(cohort.shaip.results_dir + savefilename)\n",
    "    plt.show()\n",
    "        \n",
    "# show_images(Cohort(ShaipWorkspace()), 'example_images.png')\n",
    "show_images(Cohort(ShaipWorkspace()), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Eventually we'll want to cache this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessedCohort(object):\n",
    "    \"\"\" \n",
    "    Represents cohort of data with basic pre-procession applied.  For example, deal with padding,\n",
    "    conversion to Hounsfield etc.  At this stage we are no longer concerned with file formats, directories\n",
    "    etc.\n",
    "    \"\"\"\n",
    "    downsample_factor = (4, 4)\n",
    "    imshape = tuple(512//dsf for dsf in downsample_factor)  # e.g. (128, 128)\n",
    "    \n",
    "    def __init__(self, cohort):\n",
    "        dicoms = cohort.dicoms\n",
    "        \n",
    "        self.size = cohort.size   # Number of images\n",
    "        self.ids = cohort.ids\n",
    "        self.groundtruth = cohort.groundtruth\n",
    "        self.dicoms = cohort.dicoms\n",
    "        \n",
    "        self._preprocessed_images = None\n",
    "        \n",
    "    def _preprocess_one_dicom(self, dcm):\n",
    "        \"\"\" Return a nicely normalised numpy float32 image \"\"\"\n",
    "        raw_image = dcm.pixel_array\n",
    "        padding = dcm.data_element('PixelPaddingValue').value if 'PixelPaddingValue' in dcm else None\n",
    "        # print(raw_image.dtype)\n",
    "        slope = dcm.data_element('RescaleSlope').value\n",
    "        intercept = dcm.data_element('RescaleIntercept').value\n",
    "        \n",
    "        image = np.array(raw_image, dtype=np.float32)\n",
    "        image = image * slope + intercept\n",
    "        image = np.array(image, dtype=np.float32)\n",
    "       \n",
    "        # It seems that padding value lies!  So we'll just clamp image values and hope for the best!\n",
    "        # print(\"Image (min,max) = (%6.1f, %6.1f)\" % (np.min(image), np.max(image)))\n",
    "        clip_min = -200.0\n",
    "        clip_max = 1000.0\n",
    "        image[image < clip_min] = clip_min\n",
    "        image[image > clip_max] = clip_max\n",
    "            \n",
    "        assert np.min(image) >= clip_min\n",
    "        assert np.max(image) <= clip_max\n",
    "        \n",
    "        # Finally, downscale !\n",
    "    \n",
    "        image = downscale_local_mean(image, self.downsample_factor)\n",
    "            \n",
    "        return image\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def images(self):\n",
    "        \"\"\" Lazily apply normalisation \"\"\"\n",
    "        if self._preprocessed_images is None:\n",
    "            self._preprocessed_images = [self._preprocess_one_dicom(dcm) for dcm in self.dicoms]\n",
    "        return self._preprocessed_images\n",
    "    \n",
    "def test__preprocess_one_dicom():\n",
    "    cohort = Cohort(ShaipWorkspace())\n",
    "    ppch = PreprocessedCohort(cohort)\n",
    "    dcm1 = cohort.dicoms[0]\n",
    "    image = ppch._preprocess_one_dicom(dcm1)\n",
    "    assert image.shape == PreprocessedCohort.imshape\n",
    "    plt.imshow(image)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print(SMILY, \"test__preprocess_one_dicom passed.\")\n",
    "    \n",
    "def test_preprocessed_cohort_accessors():\n",
    "    ppch = PreprocessedCohort(Cohort(ShaipWorkspace()))\n",
    "    assert len(ppch.images) == len(ppch.ids) == len(ppch.groundtruth) == ppch.size\n",
    "    print(SMILY, \"test_preprocessed_cohort_accessors passed.\")\n",
    "    \n",
    "test__preprocess_one_dicom()\n",
    "test_preprocessed_cohort_accessors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(PreprocessedCohort(Cohort(ShaipWorkspace())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset train / test split and preparation for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scaling(images):\n",
    "    \"\"\"\n",
    "    Given a list of pre-processed images (e.g. from PreprocessedCohort.images) perform\n",
    "    intensity scaling and reshaping, returning a 4D tensor (n, x, y, 1) ready for feeding to a network\n",
    "    \"\"\"\n",
    "    \n",
    "    siz = images[0].shape\n",
    "    x_data = np.array(images).reshape(-1, siz[0], siz[1], 1)\n",
    "    x_data = x_data.astype(np.float32)\n",
    "    x_data = (x_data + 100) / 150.0\n",
    "    mean, sd = np.mean(x_data), np.std(x_data)\n",
    "    min_, max_ = np.min(x_data), np.max(x_data)\n",
    "    print(\"data_scaling: shape:\", x_data.shape, \"min,max:\", (min_, max_), \"mean,sd:\", (mean, sd))\n",
    "    \n",
    "    return x_data\n",
    "\n",
    "def test_data_scaling():\n",
    "    xs, ys = 64, 128\n",
    "    im = np.random.uniform(size=(xs, ys),high=2000, low=-300)\n",
    "    n = 3\n",
    "    images = [im] * n  # test set of just 3 images\n",
    "    x_data = data_scaling(images)\n",
    "    expected_shape = (n, xs, ys, 1)\n",
    "    assert x_data.shape == expected_shape\n",
    "    assert x_data.dtype == np.float32\n",
    "    \n",
    "test_data_scaling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(image_shape):\n",
    "    input_shape = image_shape + (1,)  # e.g. (128, 128, 1)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, kernel_size=(3, 3), strides=(1, 1), activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(Conv2D(8, (3, 3), strides=(1, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "def test_build_model():\n",
    "    model = build_model((128, 128))\n",
    "    model.summary()\n",
    "    print(SMILY, \"test_build_model passed.\")\n",
    "\n",
    "test_build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "def save_model(model, fname):\n",
    "    \"\"\" Save model and wieghts to fname and fname.h5 files respectively \n",
    "    fname can include a directory which will be created if it doesn't exist\"\"\"\n",
    "    \n",
    "    directory = os.path.dirname(fname)\n",
    "    if directory and not os.path.isdir(directory):\n",
    "        print(\"Creating directory %s\" % directory)\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    model_json = model.to_json()\n",
    "    with open(fname+'.json', 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(fname+'.h5')\n",
    "    print(\"Model saved to %s[.json,.h5] files\" % fname)\n",
    "\n",
    "def load_model(fname):\n",
    "    \"\"\" Load a model from fname.json and fname.h5, and return it. \n",
    "    (Note that the loaded model must be compiled before use)\"\"\"\n",
    "    # load json and create model\n",
    "    json_file = open(fname+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(fname + '.h5')\n",
    "    print(\"Loaded model from %s[.json,.h5] files\" % fname)\n",
    "    return loaded_model\n",
    "\n",
    "def test_model_save_and_load():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(5, 1)))\n",
    "    save_model(model, 'gash/test_model')\n",
    "    model2 = load_model('gash/test_model')\n",
    "    print(SMILY, \"test_model_save_and_load passed.\")\n",
    "    \n",
    "test_model_save_and_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    \"\"\" Record and plot training progress \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.val_acc = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "        self.val_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "    def plot_training(self):\n",
    "        epochs = range(1, len(self.acc)+1)\n",
    "        plt.plot(epochs, self.acc, label='Train')\n",
    "        plt.plot(epochs, self.val_acc, label='Validation')\n",
    "        plt.ylim(0.0, 1.0)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "def test_AccuraryHistory():\n",
    "    history = AccuracyHistory()\n",
    "    \n",
    "    # Simulate some training!\n",
    "    history.on_train_begin()\n",
    "    for epoch, acc, val_acc in zip([1,2,3,4], [.6,.7,.75,.75], [.6,.65,.68,.65]):\n",
    "        log = {'acc':acc, 'val_acc':val_acc}\n",
    "        history.on_epoch_end(epoch, log)\n",
    "        \n",
    "    history.plot_training()\n",
    "    print(SMILY, \"test_AccuraryHistory passed.\")\n",
    "    \n",
    "test_AccuraryHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating results\n",
    "All results are visible from a top level 'index.html' file in the results_dir directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_static_index_html(shaip, filename):\n",
    "    \"\"\" Given filename should include the path and filename. Write the file\n",
    "    into the SHAIP results_dir directory \"\"\"\n",
    "    assert '.html' in filename\n",
    "    contents = \\\n",
    "\"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "\n",
    "<h1>Kaggle CTMI Example results</h1>\n",
    "These are results for the problem of CT/CTA detection.\n",
    "\n",
    "<h2>Data source</h2>\n",
    "\n",
    "Datasets come from the <a href=\"https://www.kaggle.com/kmader/siim-medical-images/home\">Kaggle Medical Imaging dataset</a>.  The data is originally from  <a href=\"https://wiki.cancerimagingarchive.net/display/Public/TCGA-LUAD\">The Cancer Genome Atlas LUADA</a> collection\n",
    "\n",
    "<h2> Dataset exploration</h2>\n",
    "\n",
    "<img src=\"example_images.png\">\n",
    "\n",
    "<p></p>\n",
    "\n",
    "A summary table can be seen <a href=\"summary.html\">  here </a>.\n",
    "\n",
    "<h2>Results</h2>\n",
    "\n",
    "See all results in the <a href=\"notebook.html\"> Jupuyter Notebook</a>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "    with open(shaip.results_dir + filename, 'w') as fp:\n",
    "        fp.write(contents)\n",
    "        \n",
    "def test_generate_static_index_html():\n",
    "    shaip = ShaipWorkspace();\n",
    "    generate_static_index_html(shaip, 'gash_index.html')\n",
    "    assert os.path.exists(shaip.results_dir + 'gash_index.html')\n",
    "    print(SMILY, \"test_generate_static_index_html passed\")\n",
    "    \n",
    "test_generate_static_index_html()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(shaip):\n",
    "    start = time.time()\n",
    "    # Define our SHAIP Workspace file structure\n",
    "    shaip = ShaipWorkspace()\n",
    "    \n",
    "    # Obtain the cohort of data from SHAIP\n",
    "    cohort = Cohort(shaip)\n",
    "    \n",
    "    # Show and output images and information on what we're working with\n",
    "    show_images(cohort, 'example_images.png')\n",
    "    explore_cohort(cohort, 'summary.html')\n",
    "    \n",
    "    # Perform pre-processing (not yet cached)\n",
    "    ppch = PreprocessedCohort(cohort)\n",
    "    \n",
    "    # Prepare for training - scaling and making a train/test split\n",
    "    x_data = data_scaling(ppch.images)\n",
    "    y_data = keras.utils.to_categorical(ppch.groundtruth, 2)\n",
    "    ids = ppch.ids\n",
    "    x_train, x_test, y_train, y_test, ids_train, ids_test= \\\n",
    "        train_test_split(x_data, y_data, ids, \n",
    "                         test_size=0.20, shuffle=True, random_state=21)\n",
    "    print(\"Training set: %d class 0, %d class 1\" % (np.sum(y_train[:,0]), np.sum(y_train[:,1])))\n",
    "    print(\"Testing set:  %d class 0, %d class 1\" % (np.sum(y_test[:,0]), np.sum(y_test[:,1])))\n",
    "    \n",
    "    # Build the CNN model\n",
    "    input_shape = PreprocessedCohort.imshape\n",
    "    model = build_model(input_shape)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "    history = AccuracyHistory()\n",
    "    \n",
    "    # Train and save the model\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=20,\n",
    "              shuffle=True,\n",
    "              epochs=15,\n",
    "              verbose=2,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[history])\n",
    "    save_model(model, shaip.models_dir + 'model')\n",
    "    \n",
    "    # Show some results of training\n",
    "    history.plot_training()\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    # Output some results\n",
    "    result = 'Test accuracy: %5.3f' % score[1]\n",
    "    print(result)\n",
    "    with open(shaip.results_dir + 'score.txt', 'w') as scorefp:\n",
    "        scorefp.write(result)\n",
    "    generate_static_index_html(shaip, 'index.html')\n",
    "    print(\"Done in %4.1f seconds\" % (time.time()-start))\n",
    "        \n",
    "# Lets do it!\n",
    "main(ShaipWorkspace())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
